{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from data_utils import data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the alphabet used in vectorization\n",
    "alphabet = \"abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\n",
    "char_dict = {}\n",
    "for idx, char in enumerate(alphabet):\n",
    "    char_dict[char] = idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strToIndex(s, char_dict, input_size):\n",
    "    \"\"\"\n",
    "    Convert charater to index\n",
    "    \n",
    "    Args:\n",
    "        s: string\n",
    "        char_dic: character dictionary\n",
    "        input_size: the lenght of the feature vector\n",
    "    Returns:\n",
    "        the index of the string\n",
    "    \"\"\"\n",
    "    s = s.lower()\n",
    "    m = len(s)\n",
    "    n = min(m, input_size)\n",
    "    str2index = np.zeros(input_size, dtype='int32')\n",
    "    for i in range(0, n):\n",
    "        c = s[i]\n",
    "        if c in char_dict:\n",
    "            str2index[i] = char_dict[c]\n",
    "    return str2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(path, \n",
    "              char_dict = char_dict,\n",
    "              input_size=1014):\n",
    "    \"\"\"\n",
    "    Load the data and vectorize the original text\n",
    "    \n",
    "    Args:\n",
    "        path: the path the data\n",
    "        char_dict\" the character dictionary\n",
    "        input_size: the length of the feature vector\n",
    "    Returns:\n",
    "        vectorized text and the one-hot encoding ground truth\n",
    "    \"\"\"\n",
    "    \n",
    "    char_dict = {}\n",
    "    for idx, char in enumerate(alphabet):\n",
    "        char_dict[char] = idx + 1\n",
    "    df = pd.read_pickle(path)\n",
    "    context = df.article.values\n",
    "    title = df.title.values\n",
    "    text = []\n",
    "    for i in range(len(context)):\n",
    "        c = \"\"\n",
    "        t = \"\"\n",
    "        c = c + re.sub(\"^\\s*(.-)\\s*$\", \"%1\", context[i]).replace(\"\\\\n\", \"\\n\")\n",
    "        #for t in title[i]:\n",
    "        t = t + \" \" + re.sub(\"^\\s*(.-)\\s*$\", \"%1\", title[i]).replace(\"\\\\n\", \"\\n\")\n",
    "        s = strToIndex(t+c, char_dict=char_dict, input_size=input_size)\n",
    "        text.append(s)\n",
    "    #str2idx = [strToIndex(s) for s in text]\n",
    "    return np.array(text), pd.get_dummies(df.popularity).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train = load_data('../../data/new/train.pkl')\n",
    "x_val, y_val = load_data('../../data/new/val.pkl')\n",
    "x_test, y_test = load_data('../../data/new/test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten, GlobalMaxPool1D\n",
    "from keras.layers import Convolution1D, MaxPool1D, Embedding\n",
    "from keras.layers import ThresholdedReLU, Dropout, Concatenate\n",
    "from keras.layers import AlphaDropout\n",
    "from keras.callbacks import Callback, TensorBoard, EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "INPUT_SIZE = 1014\n",
    "ALPHABET_SIZE = len(alphabet)\n",
    "EMBEEDING_SIZE = 128\n",
    "CONV_LAYER = [ [256,10], [256,7],[256,5], [256,3]]\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(CONV_LAYER):\n",
    "    \"\"\"\n",
    "    Construct the computational graph of the char-CNN\n",
    "    \n",
    "    Args:\n",
    "        CONV_LAYER: the configuration of the convolutional layer\n",
    "    Returns:\n",
    "        Keras implemented model\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(INPUT_SIZE, ), dtype='int64')\n",
    "    # Embedding Layers\n",
    "    x = Embedding(ALPHABET_SIZE+1, EMBEEDING_SIZE)(inputs)\n",
    "    \n",
    "    # Convolutional Layer\n",
    "    convoluyion_output = []\n",
    "    for num_filters, filter_width in CONV_LAYER:\n",
    "        conv = Convolution1D(filters=num_filters,\n",
    "                             kernel_size=filter_width,\n",
    "                             activation='tanh')(x)\n",
    "        pool = GlobalMaxPool1D()(conv)\n",
    "        convoluyion_output.append(pool)\n",
    "    x = Concatenate()(convoluyion_output)\n",
    "    \n",
    "    x = Dense(1024, activation='selu', kernel_initializer='lecun_normal')(x)\n",
    "    x = Dense(1024, activation='selu', kernel_initializer='lecun_normal')(x)\n",
    "    \n",
    "    # Output layer\n",
    "    predictions = Dense(3, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1014)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1014, 128)    8960        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1005, 256)    327936      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1008, 256)    229632      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1010, 256)    164096      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1012, 256)    98560       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 256)          0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 256)          0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 256)          0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 256)          0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1024)         0           global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "                                                                 global_max_pooling1d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         1049600     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         1049600     dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 3)            3075        dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,931,459\n",
      "Trainable params: 2,931,459\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(CONV_LAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class RocAucMetricCallback(Callback):\n",
    "    \"\"\"\n",
    "    Define a new callback to compute the roc auc score during the training process\n",
    "    \"\"\"\n",
    "    def __init__(self, predict_batch_size=1024, include_on_batch=False):\n",
    "        super(RocAucMetricCallback, self).__init__()\n",
    "        self.predict_batch_size=predict_batch_size\n",
    "        self.include_on_batch=include_on_batch\n",
    " \n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        pass\n",
    " \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        if(self.include_on_batch):\n",
    "            logs['roc_auc_val']=float('-inf')\n",
    "            if(self.validation_data):\n",
    "                logs['roc_auc_val']=roc_auc_score(self.validation_data[1], \n",
    "                                                  self.model.predict(self.validation_data[0],\n",
    "                                                                     batch_size=self.predict_batch_size))\n",
    " \n",
    "    def on_train_begin(self, logs={}):\n",
    "        if not ('roc_auc_val' in self.params['metrics']):\n",
    "            self.params['metrics'].append('roc_auc_val')\n",
    " \n",
    "    def on_train_end(self, logs={}):\n",
    "        pass\n",
    " \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        pass\n",
    " \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        logs['roc_auc_val']=float('-inf')\n",
    "        if(self.validation_data):\n",
    "            score = roc_auc_score(self.validation_data[1], \n",
    "                                              self.model.predict(self.validation_data[0],\n",
    "                                                                 batch_size=self.predict_batch_size))\n",
    "            logs['roc_auc_val']=score\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "tbCallBack = TensorBoard(log_dir='../../output/char_cnn', histogram_freq=0, write_graph=True, write_images=True)\n",
    "cb = [\n",
    "    RocAucMetricCallback(), # include it before EarlyStopping!\n",
    "    EarlyStopping(monitor='roc_auc_val',patience=5, verbose=2,mode='max'),\n",
    "    tbCallBack,\n",
    "    ModelCheckpoint('weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='roc_auc_val', verbose=1)    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 74996 samples, validate on 8333 samples\n",
      "Epoch 1/100\n",
      "74996/74996 [==============================] - 66s 879us/step - loss: 0.8001 - acc: 0.6156 - val_loss: 0.7341 - val_acc: 0.6502\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.770658 \n",
      "\n",
      "\n",
      "Epoch 00001: saving model to weights.01-0.73.hdf5\n",
      "Epoch 2/100\n",
      "74996/74996 [==============================] - 65s 868us/step - loss: 0.7241 - acc: 0.6553 - val_loss: 0.7833 - val_acc: 0.6376\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.778597 \n",
      "\n",
      "\n",
      "Epoch 00002: saving model to weights.02-0.78.hdf5\n",
      "Epoch 3/100\n",
      "74996/74996 [==============================] - 65s 868us/step - loss: 0.6895 - acc: 0.6778 - val_loss: 0.7366 - val_acc: 0.6475\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.791468 \n",
      "\n",
      "\n",
      "Epoch 00003: saving model to weights.03-0.74.hdf5\n",
      "Epoch 4/100\n",
      "74996/74996 [==============================] - 65s 868us/step - loss: 0.6527 - acc: 0.6998 - val_loss: 0.7078 - val_acc: 0.6756\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.795115 \n",
      "\n",
      "\n",
      "Epoch 00004: saving model to weights.04-0.71.hdf5\n",
      "Epoch 5/100\n",
      "74996/74996 [==============================] - 65s 868us/step - loss: 0.6175 - acc: 0.7195 - val_loss: 0.7244 - val_acc: 0.6760\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.796412 \n",
      "\n",
      "\n",
      "Epoch 00005: saving model to weights.05-0.72.hdf5\n",
      "Epoch 6/100\n",
      "74996/74996 [==============================] - 65s 868us/step - loss: 0.5723 - acc: 0.7445 - val_loss: 0.8306 - val_acc: 0.6588\n",
      "\n",
      " ROC-AUC - epoch: 6 - score: 0.787895 \n",
      "\n",
      "\n",
      "Epoch 00006: saving model to weights.06-0.83.hdf5\n",
      "Epoch 7/100\n",
      "74996/74996 [==============================] - 65s 868us/step - loss: 0.5309 - acc: 0.7647 - val_loss: 0.7571 - val_acc: 0.6600\n",
      "\n",
      " ROC-AUC - epoch: 7 - score: 0.784886 \n",
      "\n",
      "\n",
      "Epoch 00007: saving model to weights.07-0.76.hdf5\n",
      "Epoch 8/100\n",
      "74996/74996 [==============================] - 65s 868us/step - loss: 0.4705 - acc: 0.7980 - val_loss: 0.8880 - val_acc: 0.6207\n",
      "\n",
      " ROC-AUC - epoch: 8 - score: 0.768410 \n",
      "\n",
      "\n",
      "Epoch 00008: saving model to weights.08-0.89.hdf5\n",
      "Epoch 9/100\n",
      "74996/74996 [==============================] - 65s 868us/step - loss: 0.4262 - acc: 0.8192 - val_loss: 0.8787 - val_acc: 0.6438\n",
      "\n",
      " ROC-AUC - epoch: 9 - score: 0.771850 \n",
      "\n",
      "\n",
      "Epoch 00009: saving model to weights.09-0.88.hdf5\n",
      "Epoch 10/100\n",
      "74996/74996 [==============================] - 65s 868us/step - loss: 0.3700 - acc: 0.8456 - val_loss: 0.9101 - val_acc: 0.6484\n",
      "\n",
      " ROC-AUC - epoch: 10 - score: 0.774675 \n",
      "\n",
      "\n",
      "Epoch 00010: saving model to weights.10-0.91.hdf5\n",
      "Epoch 00010: early stopping\n",
      "Trianing time: 496.22231200000004\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "hist = model.fit(x_train, y_train,\n",
    "                 batch_size = BATCH_SIZE,\n",
    "                 epochs = 100,\n",
    "                 validation_data = (x_val, y_val),\n",
    "                 callbacks=cb,\n",
    "                 verbose=1)\n",
    "print('Trianing time:', time.clock()-start)\n",
    "\n",
    "model.save('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_train = model.predict(x_train, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_test = model.predict(x_test, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4188, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('pred_train.npy',pred_train)\n",
    "np.save('pred_test.npy', pred_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
