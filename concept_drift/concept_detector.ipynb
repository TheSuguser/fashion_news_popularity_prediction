{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>category</th>\n",
       "      <th>comments</th>\n",
       "      <th>hypes</th>\n",
       "      <th>keywords</th>\n",
       "      <th>title</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-06-06</th>\n",
       "      <td>After collaborations with DELUXE and BILLY’s, ...</td>\n",
       "      <td>[Footwear]</td>\n",
       "      <td>[These are pretty much the same colors that've...</td>\n",
       "      <td>3639</td>\n",
       "      <td>[Vans, Vans Era, Vans SK8-HI, Vans Old Skool, ...</td>\n",
       "      <td>Vans Keeps it Simple With New \"Color Theory\" R...</td>\n",
       "      <td>cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-06</th>\n",
       "      <td>Taking to London Fashion Week: Men’s to show o...</td>\n",
       "      <td>[Footwear]</td>\n",
       "      <td>[yike and yawn 2, As far as big logo sneakers ...</td>\n",
       "      <td>1046</td>\n",
       "      <td>[Nike, Nike Air Max Plus, London Fashion Week ...</td>\n",
       "      <td>ALCH Studio Displays Unseen Nike Air Max Plus ...</td>\n",
       "      <td>cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-13</th>\n",
       "      <td>Adding to its list of anticipated E3 2018 game...</td>\n",
       "      <td>[Entertainment]</td>\n",
       "      <td>[it's all about yoshimitsu]</td>\n",
       "      <td>1422</td>\n",
       "      <td>[E3, Video Games, Trailers, Sony Playstation 4...</td>\n",
       "      <td>'SOULCALIBUR VI' Set to Release With a Collect...</td>\n",
       "      <td>cold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      article  \\\n",
       "date                                                            \n",
       "2018-06-06  After collaborations with DELUXE and BILLY’s, ...   \n",
       "2018-06-06  Taking to London Fashion Week: Men’s to show o...   \n",
       "2018-06-13  Adding to its list of anticipated E3 2018 game...   \n",
       "\n",
       "                   category  \\\n",
       "date                          \n",
       "2018-06-06       [Footwear]   \n",
       "2018-06-06       [Footwear]   \n",
       "2018-06-13  [Entertainment]   \n",
       "\n",
       "                                                     comments  hypes  \\\n",
       "date                                                                   \n",
       "2018-06-06  [These are pretty much the same colors that've...   3639   \n",
       "2018-06-06  [yike and yawn 2, As far as big logo sneakers ...   1046   \n",
       "2018-06-13                        [it's all about yoshimitsu]   1422   \n",
       "\n",
       "                                                     keywords  \\\n",
       "date                                                            \n",
       "2018-06-06  [Vans, Vans Era, Vans SK8-HI, Vans Old Skool, ...   \n",
       "2018-06-06  [Nike, Nike Air Max Plus, London Fashion Week ...   \n",
       "2018-06-13  [E3, Video Games, Trailers, Sony Playstation 4...   \n",
       "\n",
       "                                                        title popularity  \n",
       "date                                                                      \n",
       "2018-06-06  Vans Keeps it Simple With New \"Color Theory\" R...       cold  \n",
       "2018-06-06  ALCH Studio Displays Unseen Nike Air Max Plus ...       cold  \n",
       "2018-06-13  'SOULCALIBUR VI' Set to Release With a Collect...       cold  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('../test/hypebeast_clean.pkl')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select the training data\n",
    "df = df.drop('2018-6-6')\n",
    "df = df['2014':'2018']\n",
    "df = df.sort_index()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X =  df.title.values + df.article.values\n",
    "y = df.popularity.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feture Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NGRAM_RANGE = (1,2)\n",
    "TOP_K = 20000\n",
    "TOKEN_MODE = 'word'\n",
    "MIN_DOCUMENT_FREQUENCY = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ngram_vectorize(train_texts, train_labels):\n",
    "    \"\"\"\n",
    "    Convert the text to the combination of unigram and bigram and select the top_k features\n",
    "    \n",
    "    Args:\n",
    "        train_texts: original text\n",
    "        train_labels: the ground truth\n",
    "    Returns:\n",
    "        X_train: the vectorized training data\n",
    "    \"\"\"\n",
    "    kwargs = {\n",
    "            'ngram_range': NGRAM_RANGE,\n",
    "            'dtype': 'int32',\n",
    "            'strip_accents': 'unicode',\n",
    "            'decode_error': 'replace',\n",
    "            'analyzer': TOKEN_MODE,\n",
    "            'min_df': MIN_DOCUMENT_FREQUENCY\n",
    "    }\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(**kwargs)\n",
    "    \n",
    "    X_train = vectorizer.fit_transform(train_texts)\n",
    "    \n",
    "    selector = SelectKBest(f_classif, k=min(TOP_K, X_train.shape[1]))\n",
    "    selector.fit(X_train, train_labels)\n",
    "    X_train = selector.transform(X_train).astype('float32')\n",
    "    \n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = ngram_vectorize(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept Drift Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 : [[ 0.87134688  0.12671007  0.00194305]] 0\n",
      "2000 : [[ 0.42178317  0.57750408  0.00071275]] 1\n",
      "3000 : [[  9.89628525e-01   1.02117627e-02   1.59712605e-04]] 1\n",
      "4000 : [[ 0.28826562  0.70536591  0.00636847]] 1\n",
      "5000 : [[  9.75029165e-01   2.44228133e-02   5.48021517e-04]] 0\n",
      "6000 : [[ 0.70622463  0.28551     0.00826537]] 1\n",
      "7000 : [[ 0.2018634   0.79429248  0.00384412]] 0\n",
      "8000 : [[ 0.18932837  0.80182705  0.00884458]] 0\n",
      "9000 : [[  9.81442862e-01   1.78237252e-02   7.33412737e-04]] 0\n",
      "10000 : [[ 0.23492397  0.7593545   0.00572153]] 0\n",
      "11000 : [[ 0.51486121  0.47662654  0.00851225]] 1\n",
      "12000 : [[ 0.08082561  0.91803268  0.00114171]] 1\n",
      "13000 : [[  9.87916020e-01   1.18650620e-02   2.18918316e-04]] 1\n",
      "14000 : [[ 0.72010112  0.27524313  0.00465575]] 1\n",
      "15000 : [[  9.92831844e-01   6.76010478e-03   4.08050894e-04]] 0\n",
      "16000 : [[ 0.81522176  0.17899864  0.0057796 ]] 0\n",
      "17000 : [[ 0.88627929  0.10720789  0.00651282]] 0\n",
      "18000 : [[ 0.98345267  0.01525267  0.00129466]] 0\n",
      "19000 : [[ 0.35838986  0.53616941  0.10544073]] 2\n",
      "20000 : [[ 0.98704634  0.01053282  0.00242084]] 0\n",
      "21000 : [[ 0.97896551  0.01546353  0.00557096]] 1\n",
      "22000 : [[ 0.24205197  0.74108876  0.01685927]] 1\n",
      "23000 : [[ 0.97690318  0.0205708   0.00252602]] 1\n",
      "24000 : [[  9.97199900e-01   2.32739660e-03   4.72703248e-04]] 1\n",
      "25000 : [[ 0.89195818  0.09624293  0.01179889]] 0\n",
      "26000 : [[ 0.31670653  0.66003069  0.02326278]] 1\n",
      "27000 : [[ 0.45603013  0.51419117  0.02977869]] 1\n",
      "28000 : [[ 0.60498276  0.348211    0.04680625]] 1\n",
      "29000 : [[ 0.21616658  0.70794113  0.07589228]] 0\n",
      "30000 : [[ 0.9860478   0.01209344  0.00185876]] 0\n",
      "31000 : [[ 0.71171704  0.26449911  0.02378384]] 0\n",
      "32000 : [[ 0.08752779  0.89030713  0.02216508]] 1\n",
      "33000 : [[ 0.47104703  0.47666811  0.05228486]] 1\n",
      "34000 : [[ 0.45665548  0.46530625  0.07803827]] 1\n",
      "35000 : [[  9.90146994e-01   9.09361743e-03   7.59388449e-04]] 1\n",
      "36000 : [[ 0.8152131  0.1639523  0.0208346]] 2\n",
      "37000 : [[ 0.98387874  0.01364501  0.00247625]] 0\n",
      "38000 : [[ 0.94977428  0.03773067  0.01249505]] 0\n",
      "39000 : [[ 0.04887188  0.89237388  0.05875424]] 0\n",
      "40000 : [[ 0.53391765  0.40933938  0.05674297]] 0\n",
      "41000 : [[ 0.99194691  0.00639761  0.00165548]] 0\n",
      "42000 : [[ 0.26969047  0.26809488  0.46221465]] 1\n",
      "43000 : [[ 0.91493387  0.07069756  0.01436856]] 0\n",
      "44000 : [[ 0.34755536  0.57508069  0.07736395]] 1\n",
      "45000 : [[ 0.75018486  0.16037378  0.08944136]] 1\n",
      "46000 : [[ 0.50189667  0.43936406  0.05873927]] 1\n",
      "47000 : [[ 0.72065451  0.26142028  0.01792521]] 1\n",
      "48000 : [[ 0.01153617  0.85886027  0.12960355]] 0\n",
      "49000 : [[ 0.08260601  0.88140953  0.03598446]] 0\n",
      "50000 : [[ 0.14793951  0.7122406   0.13981989]] 0\n",
      "51000 : [[ 0.50118836  0.43934011  0.05947153]] 0\n",
      "52000 : [[ 0.45929249  0.43146072  0.10924679]] 0\n",
      "53000 : [[ 0.39276377  0.55184174  0.05539449]] 0\n",
      "54000 : [[ 0.45269339  0.4789798   0.06832681]] 0\n",
      "55000 : [[ 0.07582585  0.88228119  0.04189296]] 0\n",
      "56000 : [[ 0.44321243  0.4529828   0.10380477]] 0\n",
      "57000 : [[ 0.54087424  0.3912901   0.06783565]] 0\n",
      "58000 : [[ 0.88110156  0.10298844  0.01591   ]] 1\n",
      "59000 : [[ 0.18492169  0.76621478  0.04886354]] 0\n",
      "60000 : [[ 0.43688217  0.49683412  0.06628371]] 1\n",
      "61000 : [[ 0.29685944  0.65756229  0.04557827]] 1\n",
      "62000 : [[ 0.09209465  0.65076407  0.25714128]] 1\n",
      "63000 : [[ 0.08690643  0.87909997  0.0339936 ]] 0\n",
      "64000 : [[ 0.84551698  0.13640858  0.01807444]] 0\n",
      "65000 : [[ 0.96930446  0.02802254  0.00267301]] 0\n",
      "66000 : [[ 0.46019793  0.46041206  0.07939001]] 0\n",
      "67000 : [[ 0.93708247  0.0554667   0.00745083]] 0\n",
      "68000 : [[ 0.83330895  0.15170058  0.01499047]] 0\n",
      "69000 : [[ 0.90834077  0.07903316  0.01262607]] 0\n",
      "70000 : [[ 0.3199804   0.64641996  0.03359963]] 1\n",
      "71000 : [[ 0.59917753  0.35684891  0.04397356]] 1\n",
      "72000 : [[ 0.09415416  0.82265844  0.0831874 ]] 0\n",
      "73000 : [[ 0.14964922  0.79881644  0.05153435]] 1\n",
      "74000 : [[ 0.21704584  0.74135663  0.04159753]] 0\n",
      "75000 : [[ 0.54658735  0.39928932  0.05412333]] 0\n",
      "76000 : [[ 0.17416832  0.7984643   0.02736738]] 0\n",
      "77000 : [[ 0.10938277  0.84407956  0.04653767]] 0\n",
      "78000 : [[ 0.59627417  0.3418231   0.06190273]] 0\n",
      "79000 : [[ 0.73142377  0.23592168  0.03265455]] 0\n",
      "80000 : [[ 0.23254465  0.73513432  0.03232103]] 0\n",
      "81000 : [[ 0.09371045  0.82772289  0.07856666]] 2\n",
      "82000 : [[ 0.62511306  0.33244732  0.04243963]] 1\n",
      "83000 : [[ 0.26159012  0.67534792  0.06306196]] 2\n",
      "84000 : [[ 0.93945246  0.05419264  0.0063549 ]] 0\n",
      "85000 : [[ 0.2839614   0.62551073  0.09052787]] 2\n",
      "86000 : [[ 0.50980006  0.38727375  0.10292619]] 1\n",
      "87000 : [[ 0.11731462  0.79990863  0.08277675]] 1\n"
     ]
    }
   ],
   "source": [
    "bl_clf = MultinomialNB(alpha=0.1)\n",
    "bl_pred = []\n",
    "bl_clf.partial_fit(X_train[:30, :], y[:30], classes=[0,1,2])\n",
    "\n",
    "for i in range(31,X_train.shape[0]):\n",
    "    bl_pred.append(bl_clf.predict_proba(X_train[i,:]))\n",
    "    bl_clf.partial_fit(X_train[i,:], [y[i]])\n",
    "    #bl_pred.append(bl_clf.predict_proba(X_train[i+1,:]))\n",
    "    \n",
    "    if i%1000==0:\n",
    "        print(i,':',bl_pred[-1], y[i+1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = np.array(bl_pred).reshape([-1,3])\n",
    "np.save('../result/concept_drift/y_pred_base_learner.npy',y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def p2i(p):\n",
    "    \"\"\"\n",
    "    One-hot encoding label\n",
    "    Args:\n",
    "        p: ground truth\n",
    "    Returns:\n",
    "        One-hot encoding labels\n",
    "    \"\"\"\n",
    "    if p=='cold':\n",
    "        return 0\n",
    "    elif p=='medium':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_true = [p2i(p) for p in y[32:]]\n",
    "np.save('../result/concept_drift/labels.npy', np.array(y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drift Detection Framework\n",
    "\n",
    "The detailed explanation of the source code is shown at DDM.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_min = 200\n",
    "s_min = 200\n",
    "p_con = -100\n",
    "store_token = None\n",
    "start_token = 0\n",
    "prob = []\n",
    "stat = []\n",
    "n = 50\n",
    "w = 1.5\n",
    "d = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/naive_bayes.py:461: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=0.1)\n",
    "clf.partial_fit(X_train[:n,:], y[:n], classes=[0,1,2])\n",
    "\n",
    "for end_token in range(n+1, X_train.shape[0]):\n",
    "    y_pred = clf.predict_proba(X_train[end_token,:])\n",
    "    \n",
    "    clf.partial_fit(X_train[end_token,:], [y[end_token]], classes=[0,1,2])\n",
    "    \n",
    "    er = 1 - y_pred[0][y[end_token]]\n",
    "    std = np.sqrt((1-er)*er/(end_token-start_token))\n",
    "    \n",
    "    s = 0\n",
    "    \n",
    "    if er<p_min:\n",
    "        p_min = er\n",
    "        s_min = std\n",
    "        #print(\"Minimum: \", end_token, p_min, s_min)\n",
    "        \n",
    "    if er + std >= p_min + w* s_min and store_token == None:\n",
    "        stoken_token = end_token\n",
    "        p_con = er\n",
    "        #print(\"Confidence level:\", end_token, er, std)\n",
    "        s=1\n",
    "    if er < p_con:\n",
    "        store_token = None\n",
    "        p_con = -100\n",
    "        #print(\"False alarm:\" , end_token)\n",
    "        s = 2\n",
    "    if er+std >= p_min + d*s_min:\n",
    "        if store_token == None:\n",
    "            start_token = end_token - n\n",
    "        else:\n",
    "            start_token = store_token\n",
    "            if end_token - store_token < n:\n",
    "                start_token = end_token - n\n",
    "        p_min = 200\n",
    "        s_min = 200\n",
    "        s = 3\n",
    "        \n",
    "        clf = MultinomialNB(alpha=0.1)\n",
    "        clf.partial_fit(X_train[start_token:end_token, :], y[start_token:end_token], classes=[0,1,2])\n",
    "        \n",
    "    prob.append(y_pred)\n",
    "    stat.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_detector(name, prob, stat):\n",
    "    stat = np.array(stat)\n",
    "    prob = np.array(prob).reshape([-1,3])\n",
    "    np.save('../result/concept_drift/{}/stat.npy'.format(name), stat)\n",
    "    np.save('../result/concept_drift/{}/prob.npy'.format(name), prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_detector('detector_4',prob, stat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
